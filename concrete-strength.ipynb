{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running TensorFlow2.2.0\nRunning KerasTuner1.0.1\nGPUs Available:1\n"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print('Running TensorFlow ', tf.__version__)\n",
    "print('Running KerasTuner ', kt.__version__)\n",
    "print(\"GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "plt.rcParams[\"font.size\"] = '12'\n",
    "plt.rcParams['image.cmap'] = 'rainbow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cement   slag  flyash  water  superplas  coarse_agg  fine_agg  age  \\\n0   540.0    0.0     0.0  162.0        2.5      1040.0     676.0   28   \n1   540.0    0.0     0.0  162.0        2.5      1055.0     676.0   28   \n2   332.5  142.5     0.0  228.0        0.0       932.0     594.0  270   \n3   332.5  142.5     0.0  228.0        0.0       932.0     594.0  365   \n4   198.6  132.4     0.0  192.0        0.0       978.4     825.5  360   \n\n   strength  \n0     79.99  \n1     61.89  \n2     40.27  \n3     41.05  \n4     44.30\nShape of data set:(1030, 9)\n"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Concrete_Data.csv')\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "print(\"Shape of data set:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality = lambda x: stats.shapiro(x.fillna(0))[1] < 0.01\n",
    "normal = pd.DataFrame(dataset)\n",
    "normal = normal.apply(test_normality)\n",
    "print(not normal.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [f for f in dataset.columns if dataset.dtypes[f] != 'object']\n",
    "\n",
    "fig, ax = plt.subplots(len(keys),2,figsize=(20,len(keys)*6))\n",
    "\n",
    "for n in range(len(keys)):\n",
    "    feat = keys[n]\n",
    "    ax[n,0].scatter(dataset[feat].values, dataset.strength.values, s=4)\n",
    "    ax[n,0].set_ylabel(\"Strength\")\n",
    "    ax[n,0].set_xlabel(feat);\n",
    "    sns.distplot(dataset[feat].dropna(), kde=True, ax=ax[n,1], color=\"limegreen\")\n",
    "    ax[n,1].set_title(\"Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 6\n",
    "import random as rn\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_x, test_x, train_y, test_y = train_test_split(dataset.drop('strength', axis=1), dataset['strength'], test_size=0.2, random_state=42)\n",
    "# print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=69)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(train_dataset.head(), train_dataset.shape)\n",
    "print(test_dataset.head(), test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop('strength')\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('strength')\n",
    "test_labels = test_dataset.pop('strength')\n",
    "\n",
    "print(train_labels.head(), train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  # return (x - train_stats['min']) / (train_stats['max'] - train_stats['min'])\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "\n",
    "print(normed_train_data.head())\n",
    "\n",
    "sns.distplot(normed_train_data['age'], kde=True, color=\"limegreen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(structure, activation, optimizer, epochs):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units = structure[1], input_dim = structure[0], activation = activation, kernel_regularizer=regularizers.l2(0.001))) \n",
    "    layers.Dropout(0.5)\n",
    "    model.add(keras.layers.Dense(units = structure[2], activation = activation, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    layers.Dropout(0.5)\n",
    "    model.add(keras.layers.Dense(units = structure[3], activation = activation, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    layers.Dropout(0.5)\n",
    "    model.add(keras.layers.Dense(units = structure[-1], activation = None))\n",
    "    \n",
    "    # Compiles the model with parameters\n",
    "    model.compile(loss = 'mse', optimizer = optimizer, metrics = ['mae', 'mse'])\n",
    "    print(model.summary(), '\\n')\n",
    "    # This tells the us training has started, so we know that it's actually running\n",
    "    print('training... ')\n",
    "    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    \n",
    "    # This trains the network\n",
    "    training_stats = model.fit(normed_train_data, train_labels, batch_size = 32, epochs = epochs, validation_split = 0.2, verbose = 0, callbacks=[early_stop])\n",
    "    \n",
    "    # Results!\n",
    "    # hist = pd.DataFrame(training_stats.history)\n",
    "    # hist['epoch'] = training_stats.epoch\n",
    "    # hist.tail()\n",
    "#     print('train_acc: %0.3f, test_acc: %0.3f' %(training_stats.history['accuracy'][-1], \n",
    "#                                                 model.evaluate(test_x, test_y, verbose = 0)[1]))\n",
    "    \n",
    "    # This returns the results and the model for use outside the function\n",
    "    return training_stats, model\n",
    "\n",
    "# Plots our evaluations in a line graph to see how they compare\n",
    "def plot_acc(train_acc, test_acc, title):\n",
    "    # Plots the training and testing accuracy lines\n",
    "    training_accuracy, = plt.plot(train_acc, label = 'Training Accuracy')\n",
    "    testing_accuracy, = plt.plot(test_acc, label = 'Testing Accuracy')\n",
    "    plt.legend(handles = [training_accuracy, testing_accuracy])\n",
    "    \n",
    "    # Plots guide lines along y = 0 and y = 1 to help visualise\n",
    "    xp = np.linspace(0, train_acc.shape[0] - 1, 10 * train_acc.shape[0])\n",
    "    plt.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\n",
    "    plt.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\n",
    "    \n",
    "    plt.xticks(range(0, train_acc.shape[0]), range(1, train_acc.shape[0] + 1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plots our evaluations in a bar chart to see how they compare\n",
    "def bar_acc(train_acc, test_acc, title, xticks):\n",
    "    index = range(1, train_acc.shape[0] + 1)\n",
    "    \n",
    "    # Plots the training and testing accuracy bars\n",
    "    training_accuracy = plt.bar(index, train_acc, 0.4, align = 'center')\n",
    "    testing_accuracy = plt.bar(index, test_acc, 0.4, align = 'edge')\n",
    "    plt.legend((training_accuracy[0], testing_accuracy[0]), ('Training Accuracy', 'Testing Accuracy'))\n",
    "    \n",
    "    plt.xticks(index, xticks)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden1 in range (128, 513, 128):\n",
    "    print('Evaluating model with %i hidden neurons... ' %hidden1, '\\n')\n",
    "    training_stats, model = train_network(structure = [8, hidden1, hidden1, hidden1, 1], activation = 'relu', optimizer = 'RMSprop', epochs = 1000)\n",
    "    hist = pd.DataFrame(training_stats.history)\n",
    "    hist['epoch'] = training_stats.epoch\n",
    "    print(hist.tail(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPa\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values Strength')\n",
    "plt.ylabel('Predictions Strength')\n",
    "lims = [0, 90]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins = 25)\n",
    "plt.xlabel(\"Prediction Error Strength\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenv7a418ffdc732437e890dd4c45e928f2c",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}